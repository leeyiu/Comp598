{
 "metadata": {
  "name": "",
  "signature": "sha256:ff3c063a55045d977232a8fb8db653fa800f8e7c3333a451020ce01e031c1da2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following function cleans any csv file which has two column, the second column containing a string in each entry. It outputs a list containing the cleaned string in each column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Input:file is the string containing the name of the file. The first line of the csv should be the headers.\n",
      "#Output: A list containing a cleaned abstract in each entry, with all punctuations removed, converted to lowercase, words of length greater than four removed and stemmed.\n",
      "\n",
      "def cleancsv(file):\n",
      "    import csv,nltk,pyprind,re\n",
      "#Read in data\n",
      "    input=csv.reader(open(file))\n",
      "#Skip the first line\n",
      "    line1=input.next()\n",
      "#Store the rows in a list\n",
      "    inputlist=list()\n",
      "    for line in input:\n",
      "        inputlist.append(line)\n",
      "#Begin Cleaning\n",
      "    cleanedinputlist=list()\n",
      "    samplesize=len(inputlist)\n",
      "    #Progress bar\n",
      "    bar=pyprind.ProgBar(samplesize, stream=1)\n",
      "    for i in range(0,samplesize):\n",
      "        item=inputlist[i]\n",
      "        abstract=item[1]\n",
      "        #tokenize \n",
      "        tokens=word_tokenize(abstract)\n",
      "        #convert text to lower case\n",
      "        abstract=[word.lower() for word in tokens]\n",
      "        #Keep words with more alphabetic characters than not, as well as those \t\t\twith more than 4 characters \n",
      "        keeplist=list()\n",
      "        for word in abstract:\n",
      "            sumalpha=sum(1 for w in word if re.search('[a-z]',w))\n",
      "            sumothers=len(word)-sumalpha\n",
      "            keeplist.append(len(word)>4 and sumalpha >sumothers)\n",
      "        trimmedlist=list()\n",
      "        for i in range(0,len(abstract)):\n",
      "            if(keeplist[i]==True):\n",
      "                trimmedlist.append(abstract[i])\n",
      "        #Stemming\n",
      "        porter=nltk.PorterStemmer()\n",
      "        stemmedlist=[porter.stem(word) for word in trimmedlist]\n",
      "        #Convert list of cleaned words into a string separated by white space\n",
      "        str1=' '.join(stemmedlist)\n",
      "        cleanedinputlist.append(str1)\n",
      "        bar.update()\n",
      "    return cleanedinputlist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the following function to write the cleaned list to file. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Input: l is the list we want to write to file, nameofoutput is the string containing the csv we want to create.\n",
      "#What it does: create a csv file with the name nameofoutput ,e.g. \"cleanedtrainset.csv\", and write the list to this file one entry at at time, such that each row of the csv file contains an entry.\n",
      "def writelist2csv(l,nameofoutput):\n",
      "    import csv \n",
      "    output=open(nameofoutput,\"w\")\n",
      "    writer=csv.writer(output,delimiter=\",\")\n",
      "    for line in l:\n",
      "        writer.writerow([line,])\n",
      "    output.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}